{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08526c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eef3b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Step 1: Load Dataset from Local Directory**\n",
    "file_path = \"IMDB Dataset1.csv\"  # ðŸ‘‰ Replace this with your actual file path\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ce34528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Step 1: Handling Null Values**\n",
    "df.dropna(inplace=True)  # Remove missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d41ef79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cf796b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Step 3: Text Preprocessing (Cleaning)**\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove special characters\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ceb387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6886cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Step 4: Convert Sentiments to Binary**\n",
    "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5abd5206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Tokenization & Padding**\n",
    "vocab_size = 6000  # âœ… Reduced vocab size for faster training\n",
    "max_length = 150  # âœ… Reduced sequence length\n",
    "embedding_dim = 64  # âœ… Smaller embedding size\n",
    "batch_size = 64 # âœ… Lower batch size for memory efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "458d7009",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df['review'])\n",
    "sequences = tokenizer.texts_to_sequences(df['review'])\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cecbc11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Train-Test Split**\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, df['sentiment'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9cbbc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Conv1D(64, 5, activation='relu'),  # Convolutional Layer\n",
    "    tf.keras.layers.GlobalMaxPooling1D(),  # Pooling Layer\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),  # Dropout for Regularization\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output Layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dd45fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Compile Model**\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8484511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.7009 - loss: 0.5360 - val_accuracy: 0.8751 - val_loss: 0.2884\n",
      "Epoch 2/4\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9108 - loss: 0.2239 - val_accuracy: 0.8813 - val_loss: 0.2827\n",
      "Epoch 3/4\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9643 - loss: 0.1116 - val_accuracy: 0.8828 - val_loss: 0.3082\n",
      "Epoch 4/4\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9896 - loss: 0.0414 - val_accuracy: 0.8812 - val_loss: 0.3823\n"
     ]
    }
   ],
   "source": [
    "# **Train Model (Fewer Epochs)**\n",
    "history = model.fit(X_train, y_train, epochs=4, batch_size=batch_size, validation_data=(X_test, y_test))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5fd34c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8838 - loss: 0.3647\n",
      "\n",
      "âœ… Test Accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "# **Evaluate Model**\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"\\nâœ… Test Accuracy: {test_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4dcc18cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# **Predictions & Metrics**\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(\"int32\").flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfef990b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Performance Metrics:\n",
      "ðŸ”¹ Accuracy: 88.12%\n",
      "ðŸ”¹ Precision: 0.88\n",
      "ðŸ”¹ Recall: 0.89\n",
      "ðŸ”¹ F1-Score: 0.88\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nâœ… Performance Metrics:\")\n",
    "print(f\"ðŸ”¹ Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"ðŸ”¹ Precision: {precision:.2f}\")\n",
    "print(f\"ðŸ”¹ Recall: {recall:.2f}\")\n",
    "print(f\"ðŸ”¹ F1-Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b437889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Number of Misclassified Samples: 1188\n"
     ]
    }
   ],
   "source": [
    "# **Step 14: Misclassified Samples**\n",
    "misclassified_indices = np.where(y_pred != y_test.to_numpy())[0]\n",
    "print(f\"\\nðŸ”¹ Number of Misclassified Samples: {len(misclassified_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05c4342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some misclassified sample indices\n",
    "num_samples_to_display = 5  # Change this number if you want to see more examples\n",
    "misclassified_samples = misclassified_indices[:num_samples_to_display]\n",
    "\n",
    "print(\"\\nðŸ”¹ Sample Misclassified Reviews:\")\n",
    "for idx in misclassified_samples:\n",
    "    print(f\"\\nðŸ”¹ Review: {df.iloc[idx]['review'][:300]}...\")  # Displaying first 300 characters\n",
    "    print(f\"   âœ… Actual Sentiment: {'Positive' if y_test.iloc[idx] == 1 else 'Negative'}\")\n",
    "    print(f\"   âŒ Predicted Sentiment: {'Positive' if y_pred[idx] == 1 else 'Negative'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "322c75cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your review: great\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Predicted Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "# Suppose your Tokenizer is called 'tokenizer'\n",
    "# Suppose your trained model is called 'model'\n",
    "\n",
    "# New input text\n",
    "new_review = input(\"Enter your review: \")\n",
    "\n",
    "# Preprocess the new input (tokenize and pad)\n",
    "new_seq = tokenizer.texts_to_sequences([new_review])\n",
    "new_padded = pad_sequences(new_seq, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "# Predict\n",
    "predicted_prob = model.predict(new_padded)[0][0]\n",
    "\n",
    "# Convert probability to class label\n",
    "predicted_sentiment = 'Positive' if predicted_prob >= 0.5 else 'Negative'\n",
    "\n",
    "# Output\n",
    "print(f\"Predicted Sentiment: {predicted_sentiment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc627722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fd6b47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
